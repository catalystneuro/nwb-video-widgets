"""NWB pose estimation video overlay widget."""

import pathlib
from typing import Optional

import anywidget
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt
import numpy as np
import traitlets


class NWBPoseEstimationWidget(anywidget.AnyWidget):
    """Video player with pose estimation overlay and camera selector.

    Overlays DeepLabCut keypoints on streaming video with support for
    multiple cameras and keypoint visibility toggles.

    Parameters
    ----------
    nwbfile : pynwb.NWBFile
        NWB file containing pose estimation in processing['pose_estimation']
    video_urls : dict
        Mapping of video names to S3/HTTP URLs.
    camera_to_video_key : dict
        Mapping from pose estimation camera names (e.g., 'LeftCamera') to
        video_urls keys (e.g., 'VideoLeftCamera').
        Example: {"LeftCamera": "VideoLeftCamera", "BodyCamera": "VideoBodyCamera"}
    keypoint_colors : str or dict, default 'tab10'
        Either a matplotlib colormap name (e.g., 'tab10', 'Set1', 'Paired') for
        automatic color assignment, or a dict mapping keypoint names to hex colors
        (e.g., {'LeftPaw': '#FF0000', 'RightPaw': '#00FF00'}).
    default_camera : str, optional
        Camera to display initially. Falls back to first available if not found.

    Example
    -------
    >>> # Using a colormap (default)
    >>> widget = NWBPoseEstimationWidget(
    ...     nwbfile=nwbfile_processed,
    ...     video_urls=video_s3_urls,
    ...     camera_to_video_key={
    ...         "LeftCamera": "VideoLeftCamera",
    ...         "BodyCamera": "VideoBodyCamera",
    ...         "RightCamera": "VideoRightCamera",
    ...     },
    ... )

    >>> # Using custom colors for specific keypoints
    >>> widget = NWBPoseEstimationWidget(
    ...     nwbfile=nwbfile_processed,
    ...     video_urls=video_s3_urls,
    ...     camera_to_video_key={...},
    ...     keypoint_colors={'LeftPaw': '#FF0000', 'RightPaw': '#00FF00'},
    ... )
    """

    selected_camera = traitlets.Unicode("").tag(sync=True)
    available_cameras = traitlets.List([]).tag(sync=True)
    camera_to_video = traitlets.Dict({}).tag(sync=True)

    # All pose data for all cameras - loaded upfront for instant camera switching
    # Structure: {camera_name: {keypoint_metadata, pose_coordinates, timestamps}}
    # TODO: For better performance with large datasets, consider binary transfer
    # using traitlets.Bytes and Float32Array views in JavaScript. See anywidget
    # patterns by Trevor Manz for reference implementation.
    all_camera_data = traitlets.Dict({}).tag(sync=True)

    show_labels = traitlets.Bool(True).tag(sync=True)
    visible_keypoints = traitlets.Dict({}).tag(sync=True)

    _esm = pathlib.Path(__file__).parent / "pose_widget.js"
    _css = pathlib.Path(__file__).parent / "pose_widget.css"

    def __init__(
        self,
        nwbfile,
        video_urls: dict[str, str],
        camera_to_video_key: dict[str, str],
        keypoint_colors: str | dict[str, str] = "tab10",
        default_camera: Optional[str] = None,
        **kwargs,
    ):
        # Parse keypoint_colors: either a colormap name (str) or explicit color dict
        if isinstance(keypoint_colors, str):
            # It's a colormap name - will assign colors automatically
            colormap_name = keypoint_colors
            custom_colors = {}
        else:
            # It's a dict of explicit colors - use tab10 for any missing keypoints
            colormap_name = "tab10"
            custom_colors = keypoint_colors

        # Get pose estimation container
        if "pose_estimation" not in nwbfile.processing:
            raise ValueError("NWB file does not contain pose_estimation processing module")
        pose_estimation = nwbfile.processing["pose_estimation"]

        # Find available cameras (those with both pose data AND video)
        # Preserve order from camera_to_video_key so first entry is default
        available_pose_cameras = set(pose_estimation.data_interfaces.keys())
        camera_to_video = {}
        available_cameras = []

        for camera_name in camera_to_video_key.keys():
            if camera_name not in available_pose_cameras:
                continue
            video_key = camera_to_video_key[camera_name]
            video_url = video_urls.get(video_key, "")
            if video_url:
                camera_to_video[camera_name] = video_url
                available_cameras.append(camera_name)

        if not available_cameras:
            raise ValueError(
                f"No cameras have both pose data and video URLs. "
                f"Pose cameras: {available_pose_cameras}, "
                f"Video keys: {list(video_urls.keys())}"
            )

        # Select default camera
        if default_camera and default_camera in available_cameras:
            selected_camera = default_camera
        else:
            selected_camera = available_cameras[0]

        # Get colormap for automatic color assignment
        cmap = plt.get_cmap(colormap_name)

        # Create pose loader closure
        def load_camera_pose_data(camera_name: str) -> dict:
            """Load pose data for a single camera.

            Returns a dict with:
            - keypoint_metadata: {name: {color, label}}
            - pose_coordinates: {name: [[x, y], ...]} as JSON-serializable lists
            - timestamps: [t0, t1, ...] as JSON-serializable list
            """
            camera_pose = pose_estimation[camera_name]

            keypoint_names = list(camera_pose.pose_estimation_series.keys())
            n_kp = len(keypoint_names)

            metadata = {}
            coordinates = {}
            timestamps = None

            for index, (series_name, series) in enumerate(camera_pose.pose_estimation_series.items()):
                short_name = series_name.replace("PoseEstimationSeries", "")

                # Get coordinates - convert NaN to None for JSON compatibility
                data = series.data[:]  # shape: (n_frames, 2)
                # Convert to list, replacing NaN with None
                coords_list = []
                for x, y in data:
                    if np.isnan(x) or np.isnan(y):
                        coords_list.append(None)
                    else:
                        coords_list.append([float(x), float(y)])
                coordinates[short_name] = coords_list

                if timestamps is None:
                    timestamps = series.timestamps[:].tolist()

                # Assign color from custom dict or colormap
                if short_name in custom_colors:
                    color = custom_colors[short_name]
                else:
                    if hasattr(cmap, "N") and cmap.N < 256:
                        rgba = cmap(index % cmap.N)
                    else:
                        rgba = cmap(index / max(n_kp - 1, 1))
                    color = mcolors.to_hex(rgba)

                metadata[short_name] = {"color": color, "label": short_name}

            return {
                "keypoint_metadata": metadata,
                "pose_coordinates": coordinates,
                "timestamps": timestamps,
            }

        # Load all camera data upfront for instant switching in JavaScript
        all_camera_data = {}
        for camera_name in available_cameras:
            all_camera_data[camera_name] = load_camera_pose_data(camera_name)

        # Initialize visibility for all keypoints across all cameras
        visible_keypoints = {}
        for camera_data in all_camera_data.values():
            for name in camera_data["keypoint_metadata"].keys():
                if name not in visible_keypoints:
                    visible_keypoints[name] = True

        # Initialize parent with computed values
        super().__init__(
            selected_camera=selected_camera,
            available_cameras=available_cameras,
            camera_to_video=camera_to_video,
            all_camera_data=all_camera_data,
            visible_keypoints=visible_keypoints,
            **kwargs,
        )
